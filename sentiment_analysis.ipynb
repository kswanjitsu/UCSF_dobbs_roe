{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import libraries, we will use transformers pipeline and a BERT model fine tuned for tweets\n",
    "## Pandas used for df manipulation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "# Set up the inference pipeline using a model from the ðŸ¤— Hub\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's wrap the sentiment analysis in a function to vectorize the application to a dataframe (parallelize for speed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's run the sentiment analysis on each tweet\n",
    "tweets = []\n",
    "def sentiment_analyzer(element):\n",
    "   try:\n",
    "     sentiment = sentiment_analysis(element)\n",
    "\n",
    "   except: # this will take a while so some rough error handling if a row fails the analysis\n",
    "     sentiment = 'error'\n",
    "\n",
    "   return sentiment\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's read in our dataframe\n",
    "### We don't need all of the data from the dataframe, just the tweets and dates for downstream analysis, let's keep the preprocessed content as well in case we need it later."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = ['date', 'rawContent', 'renderedContent', 'lang', 'preprocessedContent']\n",
    "\n",
    "df = pd.read_csv('data/filtered_df.csv',\n",
    "                 usecols=[i for i in cols],\n",
    "                 dtype={'rawContent': 'str', 'renderedContent': 'str', 'id':'float', 'lang':'str', 'preprocessedContent':'str'}\n",
    "                 )\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's apply the sentiment analysis to the dataframe, let's use the rendered content as it will include emojis and this sentiment analyzer can use emojis!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['sentiment_analysis'] = df['renderedContent'].apply(lambda x: sentiment_analyzer(x))\n",
    "df['sentiment_analysis']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## It looks like we returned a dictionary within an unneeded list, let's get rid of the list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['sentiment_analysis'] = df['sentiment_analysis'].apply(lambda x: x[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's take a peek and save the data for the ITSA analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "1648284"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "df.to_csv('data/filtered_with_sentiment_df.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}